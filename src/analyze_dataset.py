import os
import json
import pandas as pd
from pathlib import Path

def analyze_dataset():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–∑–¥–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏ —Å–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É"""
    
    print("=" * 60)
    print("–ê–ù–ê–õ–ò–ó –î–ê–¢–ê–°–ï–¢–ê")
    print("=" * 60)
    
    base_path = Path("dataset/orientations")
    data = []
    
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è–º
    for model_dir in base_path.iterdir():
        if model_dir.is_dir():
            for orientation_dir in model_dir.iterdir():
                if orientation_dir.is_dir():
                    # –ß–∏—Ç–∞–µ–º JSON —Ñ–∞–π–ª—ã
                    orientation_file = orientation_dir / "orientation.json"
                    analysis_file = orientation_dir / "analysis.json"
                    
                    if orientation_file.exists() and analysis_file.exists():
                        try:
                            with open(orientation_file, 'r', encoding='utf-8') as f:
                                orientation_data = json.load(f)
                            
                            with open(analysis_file, 'r', encoding='utf-8') as f:
                                analysis_data = json.load(f)
                            
                            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                            row = {
                                'model': model_dir.name,
                                'orientation': orientation_dir.name,
                                'rotation_x': orientation_data.get('rotation_angles', {}).get('x', 0),
                                'rotation_y': orientation_data.get('rotation_angles', {}).get('y', 0),
                                'rotation_z': orientation_data.get('rotation_angles', {}).get('z', 0),
                                'requires_supports': analysis_data.get('overhang_analysis', {}).get('requires_supports', False),
                                'max_overhang_angle': analysis_data.get('overhang_analysis', {}).get('max_overhang_angle', 0),
                                'stability_risk': analysis_data.get('stability_metrics', {}).get('stability_risk', 'unknown')
                            }
                            data.append(row)
                            
                        except Exception as e:
                            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {orientation_dir}: {e}")
    
    # –°–æ–∑–¥–∞–µ–º DataFrame
    if data:
        df = pd.DataFrame(data)
        print("\nüìä –°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –î–ê–¢–ê–°–ï–¢–ê:")
        print(df.to_string(index=False))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        df.to_csv('dataset/dataset_summary.csv', index=False, encoding='utf-8')
        print(f"\n‚úÖ –¢–∞–±–ª–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: dataset/dataset_summary.csv")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {df['model'].nunique()}")
        print(f"–í—Å–µ–≥–æ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–π: {len(df)}")
        print(f"–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–∞–º–∏: {df['requires_supports'].sum()}")
        print(f"–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏–π –±–µ–∑ –ø–æ–¥–¥–µ—Ä–∂–µ–∫: {len(df) - df['requires_supports'].sum()}")
        
    else:
        print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫.")
    
    return data

def check_stl_files():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ STL —Ñ–∞–π–ª–æ–≤"""
    print("\n" + "=" * 60)
    print("–ü–†–û–í–ï–†–ö–ê STL –§–ê–ô–õ–û–í")
    print("=" * 60)
    
    models_path = Path("dataset/models")
    orientations_path = Path("dataset/orientations")
    
    # –ò—Å—Ö–æ–¥–Ω—ã–µ –º–æ–¥–µ–ª–∏
    print("\nüìÅ –ò—Å—Ö–æ–¥–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    for stl_file in models_path.glob("*.stl"):
        size_kb = stl_file.stat().st_size / 1024
        print(f"  ‚úÖ {stl_file.name} ({size_kb:.1f} KB)")
    
    # –û—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    print("\nüìÅ –û—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    stl_count = 0
    for stl_file in orientations_path.rglob("*.stl"):
        size_kb = stl_file.stat().st_size / 1024
        print(f"  ‚úÖ {stl_file.relative_to(orientations_path)} ({size_kb:.1f} KB)")
        stl_count += 1
    
    print(f"\n–í—Å–µ–≥–æ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö STL: {stl_count}")

if __name__ == "__main__":
    analyze_dataset()
    check_stl_files()